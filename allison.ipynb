{"cells":[{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":"import pandas as pd\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.svm import SVC, NuSVC, LinearSVC\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Education</th>\n      <th>Country</th>\n      <th>Ethnicity</th>\n      <th>Nscore</th>\n      <th>Escore</th>\n      <th>Oscore</th>\n      <th>Ascore</th>\n      <th>...</th>\n      <th>Ecstasy</th>\n      <th>Heroin</th>\n      <th>Ketamine</th>\n      <th>Legalh</th>\n      <th>LSD</th>\n      <th>Meth</th>\n      <th>Mushrooms</th>\n      <th>Nicotine</th>\n      <th>Semer</th>\n      <th>VSA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>0.49788</td>\n      <td>0.48246</td>\n      <td>-0.05921</td>\n      <td>0.96082</td>\n      <td>0.12600</td>\n      <td>0.31287</td>\n      <td>-0.57545</td>\n      <td>-0.58331</td>\n      <td>-0.91699</td>\n      <td>...</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL2</td>\n      <td>CL0</td>\n      <td>CL0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>-0.07854</td>\n      <td>-0.48246</td>\n      <td>1.98437</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>-0.67825</td>\n      <td>1.93886</td>\n      <td>1.43533</td>\n      <td>0.76096</td>\n      <td>...</td>\n      <td>CL4</td>\n      <td>CL0</td>\n      <td>CL2</td>\n      <td>CL0</td>\n      <td>CL2</td>\n      <td>CL3</td>\n      <td>CL0</td>\n      <td>CL4</td>\n      <td>CL0</td>\n      <td>CL0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>0.49788</td>\n      <td>-0.48246</td>\n      <td>-0.05921</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>-0.46725</td>\n      <td>0.80523</td>\n      <td>-0.84732</td>\n      <td>-1.62090</td>\n      <td>...</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL1</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>-0.95197</td>\n      <td>0.48246</td>\n      <td>1.16365</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>-0.14882</td>\n      <td>-0.80615</td>\n      <td>-0.01928</td>\n      <td>0.59042</td>\n      <td>...</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL2</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL2</td>\n      <td>CL0</td>\n      <td>CL0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>0.49788</td>\n      <td>0.48246</td>\n      <td>1.98437</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>0.73545</td>\n      <td>-1.63340</td>\n      <td>-0.45174</td>\n      <td>-0.30172</td>\n      <td>...</td>\n      <td>CL1</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL1</td>\n      <td>CL0</td>\n      <td>CL0</td>\n      <td>CL2</td>\n      <td>CL2</td>\n      <td>CL0</td>\n      <td>CL0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>","text/plain":"   ID      Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n0   1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n1   2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n2   3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n3   4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n4   5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n\n    Oscore   Ascore  ...  Ecstasy  Heroin  Ketamine Legalh  LSD Meth  \\\n0 -0.58331 -0.91699  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n1  1.43533  0.76096  ...      CL4     CL0       CL2    CL0  CL2  CL3   \n2 -0.84732 -1.62090  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n3 -0.01928  0.59042  ...      CL0     CL0       CL2    CL0  CL0  CL0   \n4 -0.45174 -0.30172  ...      CL1     CL0       CL0    CL1  CL0  CL0   \n\n  Mushrooms Nicotine Semer  VSA  \n0       CL0      CL2   CL0  CL0  \n1       CL0      CL4   CL0  CL0  \n2       CL1      CL0   CL0  CL0  \n3       CL0      CL2   CL0  CL0  \n4       CL2      CL2   CL0  CL0  \n\n[5 rows x 32 columns]"},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":"df = pd.read_csv('drug_consumption.csv')\ndf.head()"},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Education</th>\n      <th>Country</th>\n      <th>Ethnicity</th>\n      <th>Nscore</th>\n      <th>Escore</th>\n      <th>Oscore</th>\n      <th>Ascore</th>\n      <th>...</th>\n      <th>Ecstasy</th>\n      <th>Heroin</th>\n      <th>Ketamine</th>\n      <th>Legalh</th>\n      <th>LSD</th>\n      <th>Meth</th>\n      <th>Mushrooms</th>\n      <th>Nicotine</th>\n      <th>Semer</th>\n      <th>VSA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1</td>\n      <td>0.49788</td>\n      <td>0.48246</td>\n      <td>-0.05921</td>\n      <td>0.96082</td>\n      <td>0.12600</td>\n      <td>0.31287</td>\n      <td>-0.57545</td>\n      <td>-0.58331</td>\n      <td>-0.91699</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2</td>\n      <td>-0.07854</td>\n      <td>-0.48246</td>\n      <td>1.98437</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>-0.67825</td>\n      <td>1.93886</td>\n      <td>1.43533</td>\n      <td>0.76096</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3</td>\n      <td>0.49788</td>\n      <td>-0.48246</td>\n      <td>-0.05921</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>-0.46725</td>\n      <td>0.80523</td>\n      <td>-0.84732</td>\n      <td>-1.62090</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4</td>\n      <td>-0.95197</td>\n      <td>0.48246</td>\n      <td>1.16365</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>-0.14882</td>\n      <td>-0.80615</td>\n      <td>-0.01928</td>\n      <td>0.59042</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>0.49788</td>\n      <td>0.48246</td>\n      <td>1.98437</td>\n      <td>0.96082</td>\n      <td>-0.31685</td>\n      <td>0.73545</td>\n      <td>-1.63340</td>\n      <td>-0.45174</td>\n      <td>-0.30172</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>","text/plain":"   ID      Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n0   1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n1   2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n2   3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n3   4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n4   5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n\n    Oscore   Ascore  ...  Ecstasy  Heroin  Ketamine  Legalh  LSD  Meth  \\\n0 -0.58331 -0.91699  ...        0       0         0       0    0     0   \n1  1.43533  0.76096  ...        1       0         1       0    1     1   \n2 -0.84732 -1.62090  ...        0       0         0       0    0     0   \n3 -0.01928  0.59042  ...        0       0         1       0    0     0   \n4 -0.45174 -0.30172  ...        0       0         0       0    0     0   \n\n   Mushrooms  Nicotine  Semer  VSA  \n0          0         1      0    0  \n1          0         1      0    0  \n2          0         0      0    0  \n3          0         1      0    0  \n4          1         1      0    0  \n\n[5 rows x 32 columns]"},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":"# drop rows where Semer (fake drug) is not CL0 or CL1. Assume invalid row.\ndf_clean = df.loc[(df['Semer'] == 'CL0') | (df['Semer'] == 'CL1')]\n\n# convert 'CLO' and 'CL1' into 0 and 'CL2'-'CL6' into 1\ndf_clean = df_clean.replace(to_replace=['CL0', 'CL1', 'CL2', 'CL3', 'CL4', 'CL5', 'CL6'], value=[0, 0, 1, 1, 1, 1, 1])\ndf_clean.head()"},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":"X = df_clean.drop(columns=['Meth', 'ID'])\ny = df_clean['Meth']"},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":"X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":"sm = SMOTE(random_state=1)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"]\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(kernel=\"linear\", C=0.025),\n    GaussianProcessClassifier(1.0 * RBF(1.0)),\n    DecisionTreeClassifier(max_depth=5),\n    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()]\n"},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"scores: [0.83561644 0.84703196 0.85779817 0.84633028 0.86009174]\n95% CI: 0.85  (+/- 0.02)\n"}],"source":"scores = cross_val_score(classifier, X_train_res, y_train_res, cv=5)\nprint(f\"scores: {scores}\\n95% CI: {round(scores.mean(), 2)} \",\n     f\"(+/- {round(scores.std() * 2, 2)})\")"},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Nearest Neighbors\naccuracy: 0.7382978723404255\nF1:  0.5591397849462366\nconfusion matrix: \n [[269 103]\n [ 20  78]]\nLinear SVM\naccuracy: 0.7914893617021277\nF1:  0.6230769230769231\nconfusion matrix: \n [[291  81]\n [ 17  81]]\nGaussian Process\naccuracy: 0.8063829787234043\nF1:  0.5844748858447489\nconfusion matrix: \n [[315  57]\n [ 34  64]]\nDecision Tree\naccuracy: 0.8042553191489362\nF1:  0.6290322580645161\nconfusion matrix: \n [[300  72]\n [ 20  78]]\nRandom Forest\naccuracy: 0.7957446808510639\nF1:  0.616\nconfusion matrix: \n [[297  75]\n [ 21  77]]\nAdaBoost\naccuracy: 0.823404255319149\nF1:  0.6244343891402715\nconfusion matrix: \n [[318  54]\n [ 29  69]]\nNaive Bayes\naccuracy: 0.7659574468085106\nF1:  0.5955882352941176\nconfusion matrix: \n [[279  93]\n [ 17  81]]\nQDA\naccuracy: 0.7829787234042553\nF1:  0.5853658536585366\nconfusion matrix: \n [[296  76]\n [ 26  72]]\n//anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:693: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"}],"source":"for name, clf in zip(names, classifiers):\n    clf.fit(X_train_res, y_train_res)\n    preds = clf.predict(X_test)\n    print(f\"{name}\\naccuracy: {accuracy_score(y_test, preds)}\\nF1: \",\n        f\"{f1_score(y_test, preds)}\\nconfusion matrix: \\n\", \n        f\"{confusion_matrix(y_test, preds, labels=[0, 1])}\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}